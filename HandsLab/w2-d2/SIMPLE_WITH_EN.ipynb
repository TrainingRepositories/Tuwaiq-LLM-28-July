{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd2ae51-a507-4f71-b5ef-d5e405516140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/abdulwahabmac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import  util\n",
    "\n",
    "import scipy.spatial\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15e573a-6bc4-4756-9195-ba923f76db5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2f4ccd-1eab-409c-a6fc-b105a9a8bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Example documents\n",
    "documents = [\n",
    "    \"Machine learning is fascinating.\",\n",
    "    \"Artificial Intelligence and machine learning are closely related.\",\n",
    "    \"I love programming in Python.\",\n",
    "    \"Natural Language Processing is a subset of AI.\",\n",
    "    \"Python is a versatile programming language.\"\n",
    "]\n",
    "arabic_documents_sentences = [\n",
    "    \"التعليم في المملكة العربية السعودية يشهد تطورًا كبيرًا.\",\n",
    "    \"توجد العديد من الجامعات المرموقة في السعودية.\",\n",
    "    \"الطلاب في السعودية يحصلون على تعليم عالي الجودة.\",\n",
    "    \"تشجع الحكومة السعودية على الابتكار في التعليم.\",\n",
    "    \"التكنولوجيا تلعب دورًا مهمًا في التعليم السعودي.\",\n",
    "    \"هناك العديد من المنح الدراسية المتاحة للطلاب في السعودية.\",\n",
    "    \"التعليم الإلكتروني أصبح شائعًا في المملكة.\",\n",
    "    \"تقدم المدارس في السعودية مناهج متنوعة وشاملة.\",\n",
    "    \"التعليم الفني والمهنى يحظى بأهمية كبيرة في السعودية.\",\n",
    "    \"اللغة الإنجليزية تُدرّس بشكل مكثف في المدارس السعودية.\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b543717e-0424-4e9d-829b-d168581176c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Encode the documents using SentenceTransformers\n",
    "document_embeddings = model.encode(documents, convert_to_tensor=True)\n",
    "\n",
    "# Create a TF-IDF Vectorizer and fit on the documents\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec815f4c-b2c6-4895-ad3b-eb4ade596036",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_query(query):\n",
    "    # Tokenization, stop word removal, and stemming\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = query.lower().split()\n",
    "    filtered_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d90b7b-5a24-41bd-a8bf-15f44f2011ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hybrid_search(query, top_k=3, weight_st=0.5, weight_tfidf=0.5):\n",
    "    # Encode the query using SentenceTransformers\n",
    "    query_preprocessed = preprocess_query(query)\n",
    "    query_embedding = model.encode([query_preprocessed], convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarities between the query and the documents using SentenceTransformers\n",
    "    cosine_scores = util.pytorch_cos_sim(query_embedding, document_embeddings)[0]\n",
    "\n",
    "    # Transform the query using the TF-IDF vectorizer\n",
    "    query_tfidf = tfidf_vectorizer.transform([query_preprocessed])\n",
    "\n",
    "    # Calculate cosine similarity between the query and the documents using TF-IDF\n",
    "    tfidf_similarities = cosine_similarity(query_tfidf, tfidf_matrix)[0]\n",
    "    #print(tfidf_similarities)\n",
    "\n",
    "    # Combine the scores with weights\n",
    "    combined_scores = (weight_st * cosine_scores.cpu().numpy() + weight_tfidf * tfidf_similarities) / (weight_st + weight_tfidf)\n",
    "    #print(combined_scores)\n",
    "\n",
    "    # Normalize scores (optional)\n",
    "    combined_scores = (combined_scores - np.min(combined_scores)) / (np.max(combined_scores) - np.min(combined_scores))\n",
    "\n",
    "    # Find the top_k highest scores\n",
    "    top_results = np.argpartition(-combined_scores, range(top_k))[:top_k]\n",
    "    #print(top_results)\n",
    "\n",
    "    print(f\"Query: {query}\\nTop {top_k} most similar documents:\")\n",
    "    for idx in top_results:\n",
    "        print(f\"Document: {documents[idx]}, Combined Score: {combined_scores[idx]:.4f}\")\n",
    "\n",
    "    return top_results, combined_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad76e4c6-93ef-4305-ac11-fbca9d393568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or type 'exit' to quit):  love\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: love\n",
      "Top 3 most similar documents:\n",
      "Document: I love programming in Python., Combined Score: 1.0000\n",
      "Document: Machine learning is fascinating., Combined Score: 0.1012\n",
      "Document: Artificial Intelligence and machine learning are closely related., Combined Score: 0.0150\n",
      "Query: love\n",
      "Top 3 most similar documents:\n",
      "Document: I love programming in Python., Combined Score: 1.0000\n",
      "Document: Machine learning is fascinating., Combined Score: 0.1012\n",
      "Document: Artificial Intelligence and machine learning are closely related., Combined Score: 0.0150\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or type 'exit' to quit):  AI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: AI\n",
      "Top 3 most similar documents:\n",
      "Document: Natural Language Processing is a subset of AI., Combined Score: 1.0000\n",
      "Document: Artificial Intelligence and machine learning are closely related., Combined Score: 0.3703\n",
      "Document: Machine learning is fascinating., Combined Score: 0.2793\n",
      "Query: AI\n",
      "Top 3 most similar documents:\n",
      "Document: Natural Language Processing is a subset of AI., Combined Score: 1.0000\n",
      "Document: Artificial Intelligence and machine learning are closely related., Combined Score: 0.3703\n",
      "Document: Machine learning is fascinating., Combined Score: 0.2793\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or type 'exit' to quit):  EXIT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage with evaluation:\n",
    "while True:\n",
    "    user_query = input(\"Enter your query (or type 'exit' to quit): \")\n",
    "    if user_query.lower() == 'exit':\n",
    "        break\n",
    "    hybrid_search(user_query)\n",
    "\n",
    "    predicted_ranks, _ = hybrid_search(user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0812df-0367-43b5-ac32-2c3209cfc57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c280a-3d1b-4e6d-8a11-d370849d1d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f86a7-05d2-4909-95d2-a2a7272097b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
