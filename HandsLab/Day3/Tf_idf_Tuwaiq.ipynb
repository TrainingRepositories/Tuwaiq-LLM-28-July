{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KRtYu_yI35fx",
    "outputId": "7283ed92-1536-407d-8179-08e7eb6f9a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 'weather', 'is')\n",
      "('weather', 'is', 'warm')\n",
      "('is', 'warm', 'and')\n",
      "('warm', 'and', 'sunny')\n",
      "('and', 'sunny', 'today')\n",
      "('sunny', 'today', 'so')\n",
      "('today', 'so', 'we')\n",
      "('so', 'we', 'went')\n",
      "('we', 'went', 'out')\n",
      "('went', 'out', 'today.')\n",
      "('out', 'today.', 'But')\n",
      "('today.', 'But', 'tomorrow')\n",
      "('But', 'tomorrow', 'it')\n",
      "('tomorrow', 'it', 'will')\n",
      "('it', 'will', 'rain')\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "sentence = \"The weather is warm and sunny today so we went out today. But tomorrow it will rain\"\n",
    "n = 3\n",
    "unigrams = ngrams(sentence.split(), n)\n",
    "for grams in unigrams:\n",
    "  print (grams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDafyYJt4aJX",
    "outputId": "e3790063-edc9-4ad8-c5ad-2f789397fa92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({('My', 'address'): {'is': 1.0},\n",
       "              ('address', 'is'): {'Tuwaiq': 1.0},\n",
       "              ('is', 'Tuwaiq'): {'Academy.The': 1.0},\n",
       "              ('Tuwaiq', 'Academy.The'): {'weather': 1.0},\n",
       "              ('Academy.The', 'weather'): {'is': 1.0},\n",
       "              ('weather', 'is'): {'warm': 0.25, 'colder': 0.5, 'so': 0.25},\n",
       "              ('is', 'warm'): {'and': 1.0},\n",
       "              ('warm', 'and'): {'sunny': 1.0},\n",
       "              ('and', 'sunny'): {'today': 1.0},\n",
       "              ('sunny', 'today'): {'so': 1.0},\n",
       "              ('today', 'so'): {'we': 1.0},\n",
       "              ('so', 'we'): {'went': 1.0},\n",
       "              ('we', 'went'): {'out': 1.0},\n",
       "              ('went', 'out'): {'today.': 1.0},\n",
       "              ('out', 'today.'): {'But': 1.0},\n",
       "              ('today.', 'But'): {'tomorrow': 1.0},\n",
       "              ('But', 'tomorrow'): {'it': 1.0},\n",
       "              ('tomorrow', 'it'): {'will': 1.0},\n",
       "              ('it', 'will'): {'rain.': 1.0},\n",
       "              ('will', 'rain.'): {'The': 1.0},\n",
       "              ('rain.', 'The'): {'weather': 1.0},\n",
       "              ('The', 'weather'): {'is': 1.0},\n",
       "              ('is', 'colder'): {'day': 0.5, 'before': 0.5},\n",
       "              ('colder', 'day'): {'after.': 1.0},\n",
       "              ('day', 'after.'): {'The': 1.0},\n",
       "              ('after.', 'The'): {'weather': 1.0},\n",
       "              ('is', 'so'): {'good.': 1.0},\n",
       "              ('so', 'good.'): {'The': 1.0},\n",
       "              ('good.', 'The'): {'weather': 1.0}})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt: generate proability distribution for next word prediction for ngram of 3\n",
    "\n",
    "from nltk import ngrams\n",
    "from collections import defaultdict\n",
    "\n",
    "sentence = \"My address is Tuwaiq Academy.The weather is warm and sunny today so we went out today. But tomorrow it will rain. The weather is colder day after. The weather is so good. The weather is colder before\"\n",
    "n = 3\n",
    "\n",
    "ngram_counts = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "total_counts = defaultdict(lambda: 0)\n",
    "\n",
    "words = sentence.split()\n",
    "for i in range(len(words) - n + 1):\n",
    "  ngram = tuple(words[i:i+n-1])\n",
    "  next_word = words[i+n-1]\n",
    "  ngram_counts[ngram][next_word] += 1\n",
    "  total_counts[ngram] += 1\n",
    "\n",
    "prob_dist = defaultdict(lambda: {})\n",
    "for ngram, next_word_counts in ngram_counts.items():\n",
    "  for next_word, count in next_word_counts.items():\n",
    "    prob_dist[ngram][next_word] = count / total_counts[ngram]\n",
    "\n",
    "prob_dist.keys().mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGgB1MXWlz7R",
    "outputId": "98040150-d637-4a7b-9f3a-c18410d4d038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corpus = [\n",
    " 'This is the first, document.',\n",
    " 'This document is the second document.',\n",
    " 'And this is the third one.',\n",
    " 'Is this the first document?',\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "txd2OZfymFyC",
    "outputId": "4f3b56b4-dfba-4e89-a775-4b273a10b9e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  document  first  is  one  second  the  third  this\n",
       "0    0         1      1   1    0       0    1      0     1\n",
       "1    0         2      0   1    0       1    1      0     1\n",
       "2    1         0      0   1    1       0    1      1     1\n",
       "3    0         1      1   1    0       0    1      0     1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(corpus)\n",
    "pd.DataFrame(X.A, columns=vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jVbEwmHemJ57",
    "outputId": "79061141-7634-4f23-8e59-bbe1e4918605"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catch</th>\n",
       "      <th>eat</th>\n",
       "      <th>fish</th>\n",
       "      <th>hard</th>\n",
       "      <th>hyperparameter</th>\n",
       "      <th>people</th>\n",
       "      <th>piano</th>\n",
       "      <th>tune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.534</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   catch    eat   fish   hard  hyperparameter  people  piano   tune\n",
       "0  0.000  0.000  0.000  0.000           0.820   0.000  0.000  0.573\n",
       "1  0.000  0.000  0.350  0.000           0.000   0.000  0.622  0.701\n",
       "2  0.380  0.471  0.796  0.000           0.000   0.000  0.000  0.000\n",
       "3  0.000  0.000  0.373  0.000           0.534   0.661  0.000  0.373\n",
       "4  0.534  0.000  0.373  0.661           0.000   0.000  0.000  0.373"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "\"Tune a hyperparameter.\",\n",
    "\"You can tune a piano but you can't tune a fish.\",\n",
    "           \"Fish who eat fish, catch fish.\",\n",
    "\"People can tune a fish or a hyperparameter.\",\n",
    "           \"It is hard to catch fish and tune it.\",]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "df = pd.DataFrame(np.round(X.A,3),columns=vectorizer.get_feature_names_out())\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>added</th>\n",
       "      <th>adding</th>\n",
       "      <th>catch</th>\n",
       "      <th>eat</th>\n",
       "      <th>fish</th>\n",
       "      <th>hard</th>\n",
       "      <th>hyperparameter</th>\n",
       "      <th>im</th>\n",
       "      <th>people</th>\n",
       "      <th>piano</th>\n",
       "      <th>pluse</th>\n",
       "      <th>tune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.418</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   added  adding  catch    eat   fish   hard  hyperparameter     im  people  \\\n",
       "0  0.000   0.000  0.000  0.000  0.000  0.000           0.646  0.000   0.000   \n",
       "1  0.000   0.456  0.000  0.000  0.257  0.000           0.217  0.456   0.000   \n",
       "2  0.418   0.000  0.337  0.418  0.706  0.000           0.199  0.000   0.000   \n",
       "3  0.000   0.000  0.000  0.000  0.413  0.000           0.349  0.000   0.733   \n",
       "4  0.000   0.000  0.430  0.000  0.301  0.534           0.254  0.000   0.000   \n",
       "\n",
       "   piano  pluse   tune  \n",
       "0  0.000  0.000  0.764  \n",
       "1  0.456  0.000  0.514  \n",
       "2  0.000  0.000  0.000  \n",
       "3  0.000  0.000  0.413  \n",
       "4  0.000  0.534  0.301  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "\"Tune a hyperparameter.\",\n",
    "\"You can tune a piano but you can't tune a fish. im adding hyperparameter\",\n",
    "           \"Fish who eat fish, catch fish. hyperparameter added\",\n",
    "\"People can tune a fish or a hyperparameter.\",\n",
    "           \"It is hard to catch fish and tune it. pluse hyperparameter\",]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "df = pd.DataFrame(np.round(X.A,3),columns=vectorizer.get_feature_names_out())\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we have a paragraph of text related to Saudi Vision 2030\n",
    "# We tokenize the paragraph into sentences and store them in a list called 'sentences'\n",
    "paragraph = \"Saudi Vision 2030 is a strategic framework aimed at reducing Saudi Arabia's dependence on oil, \\\n",
    "diversifying its economy and developing public service sectors. It encompasses various initiatives \\\n",
    "to achieve long-term goals such as promoting tourism, enhancing eduwomenion, and fostering innovation.\"\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "# Tokenize each sentence into words and store them in a list of lists called 'tokenized_sentences'\n",
    "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.3.3'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train a Word2Vec model on the 'sentences' data\n",
    "# The model has parameters like embedding size of 100, window size of 5, and is trained for 10 iterations\n",
    "from gensim.models import Word2Vec\n",
    "# Create CBOW model\n",
    "w2v_CBOW = Word2Vec(tokenized_sentences, vector_size= 20, min_count=1, window=5,)\n",
    "# Create Skip Gram model\n",
    "w2v_SG = Word2Vec(tokenized_sentences, min_count=1, vector_size=20, window=5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_SG.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
